model:
  model_name_or_path: klue/roberta-large
  config_name: null
  tokenizer_name: null


data:
  dataset_name: ../data/train_preprocessed
  preprocessing_num_workers: null
  max_seq_length: 384
  pad_to_max_length: false
  doc_stride: 96
  max_answer_length: 30
  eval_retrieval: true
  num_clusters: 64
  top_k_retrieval: 10
  use_faiss: false

train:
  output_dir: ./models/train_dataset
  do_train: true
  do_eval: true
  overwrite_output_dir: true
  report_to: 'wandb'
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 4
  logging_strategy: 'steps'
  logging_steps: 50
  evaluation_strategy: 'epoch'
  save_strategy: 'epoch'
  save_total_limit: 1
  learning_rate: 9e-6
  num_train_epochs: 3
  warmup_steps: 300
  seed: 42
  dataloader_num_workers: 4
  logging_first_step: true
  fp16: false
  gradient_accumulation_steps: 4
  